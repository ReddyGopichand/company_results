{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPl9eCYvz7XjdMfq9NOhDel",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReddyGopichand/company_results/blob/main/company_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWX8huofkbus",
        "outputId": "6324dd81-5af9-429b-cd55-819669161b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "129 companies\n",
            "missed ['Acrow India', 'Agio Paper', 'Alpha Hi-Tech', 'Arcee Ind', 'Arfin India', 'Asutosh Ent', 'Bengal Steel', 'Bhudevi Infra', 'Bothra Metals', 'Bridge Sec', 'Brilliant Port', 'BWL', 'Coastal Roadway', 'Danube Ind.', 'Deccan Bearings', 'Decorous Invest', 'Dhanlaxmi Bank', 'Easy Fincorp', 'Empire Ind', 'Fusion Micro', 'Golkunda Diamon', 'Govind Poy Oxyg', 'GSB Finance', 'Guj Inject Kera', 'Guj Stat Fin', 'Haryana Capfin', 'Hit Kit Global', 'India Gelatine', 'Indokem', 'Insolation Ener', 'Jackson Invt', 'Jattashankar', 'Kakatiya Cement', 'Likhami Consult', 'Lotus Chocolate', 'Narendra Prop', 'National Fittin', 'Net Pix', 'Nirav Comm', 'Oswal Leasing', 'Otco Intl', 'Pecos Hotels', 'Premier Polyfil', 'Pushpsons Ind', 'Quality RO', 'Radiant Cash', 'Rajath Finance ', 'Ravalgaon Sugar', 'Real Touch Fin', 'Ritco Logistics', 'Rungta Irrig', 'RUSTOMJEE', 'Sadhna Broadcas', 'Sagar Product', 'SPL Industries', 'Sri Nachammai', 'SSK Lifestyles', 'Sun Pharma Adv', 'Sun Retail ', 'Supershakti Met', 'Suryo Food', 'Swadeshi Polyte', 'Swagtam Trading', 'T Spirutual', 'Thangamayil', 'Tilak Ventures', 'Transoceanic', 'Unick Fix-A- Fo', 'Upsurge Invest', 'Vaswani Ind', 'VB Desai Fin', 'Veer Energy', 'Veerhealth Care', 'WAAREE  TECH']\n",
            "[(7333, 'SJVN'), (224, 'EIH'), (116, 'RACL Geartech'), (48, 'Arihant Super'), (42, 'Aditya Birla F'), (33, 'JTEKT India '), (33, 'CG-Vak Software'), (30, 'Ramcoind'), (16, 'Spencer Retail'), (16, 'Orient Abrasive'), (13, 'Capri Global'), (9, 'Federal-Mogul'), (7, 'HEG'), (-1, 'Nacl Industries'), (-5, 'Indiabulls Hsg'), (-12, 'Camlin Fine'), (-16, 'Bharat Agri'), (-19, 'Indian Toners'), (-21, 'Xpro India'), (-27, 'PB Fintech'), (-28, 'CESC'), (-30, 'Guj Alkali'), (-30, 'Garware Technic'), (-33, 'Odyssey Corp'), (-34, 'Borosil Ltd.'), (-46, 'GPT Infra'), (-49, 'HCL Info'), (-58, 'Sicagen India'), (-62, 'Shree Cements'), (-66, 'Compucom Soft'), (-95, 'Standard Ind'), (-95, 'Finolex Ind'), (-96, 'Span Diagnostic'), (-100, 'Prabhat Technol'), (-100, 'Atlanta'), (-106, 'Hind Aluminium'), (-133, 'Jetking Info'), (-142, 'Asian Hotel (E)'), (-180, 'BPCL')]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def avg_f(l):\n",
        "    if len(l) != 5:\n",
        "        raise Exception(\"not 5\")\n",
        "    base = l[-2]\n",
        "    recent_quarters = l[:3]\n",
        "    if base == 0:\n",
        "        return\n",
        "    # if base > max(recent_quarters):\n",
        "    #     return\n",
        "    per_inc = [(q-base)/base for q in recent_quarters]\n",
        "    return sum(per_inc)/len(per_inc)\n",
        "\n",
        "\n",
        "def get_net_profit(html_string):\n",
        "    # Parse the HTML string using BeautifulSoup\n",
        "    soup = BeautifulSoup(html_string, 'html.parser')\n",
        "\n",
        "    # Extract the contents of the element selector '#income_statement table tr'\n",
        "    # table_rows = soup.select('#income_statement table tr')\n",
        "\n",
        "    # print(table_rows)\n",
        "    # # Print the contents of the table rows\n",
        "    # for row in table_rows:\n",
        "    #     print(row)\n",
        "    tags = soup.select('#C-3-income-graphData')\n",
        "    tag = tags[0]\n",
        "    data = json.loads(tag.contents[0])\n",
        "    return data['net-profit']\n",
        "\n",
        "def get_company_scid(url):\n",
        "    html = requests.get(url).text\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    tags = soup.select('#ap_sc_id')\n",
        "    try:\n",
        "        return tags[0].get_attribute_list('value')\n",
        "    except:\n",
        "        return 'gopi'\n",
        "\n",
        "def get_companies(html_string):\n",
        "    # Parse the HTML string using BeautifulSoup\n",
        "    soup = BeautifulSoup(html_string, 'html.parser')\n",
        "\n",
        "    # Extract the contents of the element selector '#income_statement table tr'\n",
        "    # table_rows = soup.select('#income_statement table tr')\n",
        "\n",
        "    # print(table_rows)\n",
        "    # # Print the contents of the table rows\n",
        "    # for row in table_rows:\n",
        "    #     print(row)\n",
        "    selector = '.scroll-pane.MT5'\n",
        "    tags = soup.select(selector)\n",
        "    todays, tomorrows = tags[0], tags[1]\n",
        "    companies = []\n",
        "    for anchor in tomorrows.select('table tr td:first-child a'):\n",
        "        # code = anchor.get_attribute_list('href')[0].split('/')[-1]\n",
        "        code = get_company_scid(anchor.get_attribute_list('href')[0])\n",
        "        if type(code) == list:\n",
        "            code = code[0]\n",
        "        name = anchor.contents[0]\n",
        "        companies.append((code,name))\n",
        "        # print(code,name)\n",
        "    return companies\n",
        "    # return todays\n",
        "    # data = json.loads(todays.contents[0])\n",
        "    # print(data['net-profit'])\n",
        "\n",
        "def get_url_content(url):\n",
        "    # get_urls(open('response.html').read())\n",
        "    # url = 'https://www.moneycontrol.com/india/stockpricequote/banks-private-sector/hdfcbank/HDF01'\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            return response.text\n",
        "        else:\n",
        "            print(f'Response code {response.status_code}')\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "\n",
        "def main():\n",
        "    companies_url = 'https://www.moneycontrol.com/markets/earnings/?classic=true'\n",
        "    result = []\n",
        "    companies = get_companies(get_url_content(companies_url))\n",
        "    print(len(companies),'companies')\n",
        "    missed_companies = []\n",
        "    neglected_companies = []\n",
        "    for company_code, company_name in companies:\n",
        "        url = 'https://www.moneycontrol.com/mc/widget/mcfinancials/getFinancialData?classic=true&referenceId=income&requestType=C&scId='+company_code+'&frequency=3'\n",
        "        try:\n",
        "            net_profit = [int(i) for i in get_net_profit(get_url_content(url))]\n",
        "            avg_inc = avg_f(net_profit)\n",
        "            if avg_inc:\n",
        "                result.append((int(avg_inc*100),company_name))\n",
        "            else:\n",
        "                neglected_companies.append(company_name)\n",
        "        except Exception as e:\n",
        "            \n",
        "           \n",
        "            missed_companies.append(company_name)\n",
        "    result.sort(reverse=True)\n",
        "    print(\"missed\",missed_companies)\n",
        "    # print('neglected',neglected_companies)\n",
        "    print(result)\n",
        "main()"
      ]
    }
  ]
}